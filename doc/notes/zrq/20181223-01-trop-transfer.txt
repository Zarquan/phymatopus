#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2018, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# -----------------------------------------------------
# Load our libvirt configuration.
#[user@trop03]

    source "${HOME}/libvirt.settings"

# -----------------------------------------------------
# Configure our SSH settings.
#[user@trop03]

    sshuser=Stevedore
    sshopts=(
        '-A'
        '-o LogLevel=ERROR'
        '-o CheckHostIP=no'
        '-o UserKnownHostsFile=/dev/null'
        '-o StrictHostKeyChecking=no'
        )

    scpopts=(
        '-o LogLevel=ERROR'
        '-o CheckHostIP=no'
        '-o UserKnownHostsFile=/dev/null'
        '-o StrictHostKeyChecking=no'
        )

# -----------------------------------------------------
# Assign our virtual machine names.
#[user@trop03]

    kfnames=(
        Stedigo
        Angece
        Edwalafia
        Onoza
        )

    zknames=(
        Fosauri
        Marpus
        Byflame
        )

    mmnames=(
        Afoaviel
        Rusaldez
        )

# -----------------------------------------------------
# Sed script to indent output.
#[user@laptop]
#
#    sed -i '
#        /^--START--$/,/^--STOP--$/ {
#            s/^\(.*\)/    >   \1/
#            }
#        ' 20181221-01-trop-transfer.txt
#
#--START--
#--STOP--
#

# -----------------------------------------------------
# Check containers on our Kafka nodes.
#[user@trop03]

    for vmname in ${kfnames[@]}
        do
            echo "---- ----"
            ssh \
                ${sshopts[*]} \
                ${sshuser:?}@${vmname:?} \
                    "
                    hostname
                    docker ps -a
                    "
        done


--START--
---- ----
Stedigo
CONTAINER ID        IMAGE                         COMMAND                  CREATED             STATUS                  PORTS               NAMES
528f5c8d6a84        confluentinc/cp-kafka:4.1.1   "/etc/confluent/dock…"   11 days ago         Exited (1) 5 days ago                       stevedore_emily_1
---- ----
Angece
CONTAINER ID        IMAGE                         COMMAND                  CREATED             STATUS                  PORTS               NAMES
54ab40521deb        confluentinc/cp-kafka:4.1.1   "/etc/confluent/dock…"   11 days ago         Exited (1) 5 days ago                       stevedore_emily_1
---- ----
Edwalafia
CONTAINER ID        IMAGE                         COMMAND                  CREATED             STATUS              PORTS                              NAMES
4af2d612c94e        confluentinc/cp-kafka:4.1.1   "/etc/confluent/dock…"   11 days ago         Up 11 days          0.0.0.0:9092-9093->9092-9093/tcp   stevedore_emily_1
---- ----
Onoza
CONTAINER ID        IMAGE                         COMMAND                  CREATED             STATUS                  PORTS               NAMES
e02f40328809        confluentinc/cp-kafka:4.1.1   "/etc/confluent/dock…"   11 days ago         Exited (1) 5 days ago                       stevedore_emily_1
--STOP--


# -----------------------------------------------------
# Check the disc space on our Kafka nodes.
#[user@trop03]

    for vmname in ${kfnames[@]}
        do
            ssh \
                ${sshopts[*]} \
                ${sshuser:?}@${vmname:?} \
                    "
                    echo \"---- ---- ---- ----\"
                    echo \"[\$(hostname)][\$(date)]\"
                    echo \"---- ----\"
                    df -h /
                    echo \"---- ----\"
                    df -h \"/data1-01\"
                    echo "---- ----"
                    df -h \"/data2-01\"
                    "
        done


--START--
---- ---- ---- ----
[Stedigo][Sun 23 Dec 12:55:03 GMT 2018]
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda3       6.8G  2.5G  3.8G  39% /
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdc         32G   31G   48K 100% /data1-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdd         32G   31G   56K 100% /data2-01
---- ---- ---- ----
[Angece][Sun 23 Dec 12:55:04 GMT 2018]
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda3       6.8G  2.4G  3.9G  39% /
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdc         32G   31G   20K 100% /data1-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdd         32G   31G   12K 100% /data2-01
---- ---- ---- ----
[Edwalafia][Sun 23 Dec 12:55:04 GMT 2018]
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda3       6.8G  2.5G  3.8G  40% /
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdc         32G   31G  764K 100% /data1-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdd         32G   31G   44K 100% /data2-01
---- ---- ---- ----
[Onoza][Sun 23 Dec 12:55:05 GMT 2018]
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda3       6.8G  2.4G  3.9G  39% /
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdc         32G   31G   28K 100% /data1-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdd         32G   31G   16K 100% /data2-01
--STOP--


# -----------------------------------------------------
# Stop kafka on each node.
#[user@trop03]

    for vmname in ${kfnames[@]}
        do
            echo "---- ----"
            ssh \
                ${scpopts[*]} \
                ${sshuser:?}@${vmname:?} \
                "
                hostname
                docker-compose \
                    --file kafka.yml \
                    down
                "
        done


--START--
---- ----
Stedigo
Removing stevedore_emily_1 ... done
Removing network stevedore_default
---- ----
Angece
Removing stevedore_emily_1 ... done
Removing network stevedore_default
---- ----
Edwalafia
Stopping stevedore_emily_1 ... done
Removing stevedore_emily_1 ... done
Removing network stevedore_default
---- ----
Onoza
Removing stevedore_emily_1 ... done
Removing network stevedore_default
--STOP--


# -----------------------------------------------------
# Create lists of devices and mount points.
#[user@trop03]

    source "${HOME}/libvirt.settings"

    volnum=02
    volsize=64G

    unset volpools
    volpools=(
        data1
        data2
        )

    unset voldevs
    declare -A voldevs=(
        [data1]=vde
        [data2]=vdf
        )

    unset volmnts
    declare -A volmnts=(
        [data1]=/data1-02
        [data2]=/data2-02
        )


# -----------------------------------------------------
# Create a new volume for each Kafka node.
#[user@trop03]


    for vmname in ${kfnames[@]}
        do
            echo "---- ----"
            echo "vmname [${vmname}]"
            for volpool in ${volpools[@]}
                do
                    echo "----"
                    volname=${vmname:?}-${volpool:?}-${volnum:?}.qcow
                    echo "volpool [${volpool}]"
                    echo "volname [${volname}]"
                    virsh \
                        --connect ${connection:?} \
                        vol-create-as \
                            ${volpool:?} \
                            ${volname:?} \
                            ${volsize} \
                            --allocation 0 \
                            --format qcow2

                    virsh \
                        --connect ${connection:?} \
                        vol-info \
                            --pool "${volpool:?}" \
                            ${volname:?}

                done
        done

--START--
---- ----
vmname [Stedigo]
----
volpool [data1]
volname [Stedigo-data1-02.qcow]
Vol Stedigo-data1-02.qcow created

Name:           Stedigo-data1-02.qcow
Type:           file
Capacity:       64.00 GiB
Allocation:     196.00 KiB

----
volpool [data2]
volname [Stedigo-data2-02.qcow]
Vol Stedigo-data2-02.qcow created

Name:           Stedigo-data2-02.qcow
Type:           file
Capacity:       64.00 GiB
Allocation:     196.00 KiB

---- ----
vmname [Angece]
----
volpool [data1]
volname [Angece-data1-02.qcow]
Vol Angece-data1-02.qcow created

Name:           Angece-data1-02.qcow
Type:           file
Capacity:       64.00 GiB
Allocation:     196.00 KiB

----
volpool [data2]
volname [Angece-data2-02.qcow]
Vol Angece-data2-02.qcow created

Name:           Angece-data2-02.qcow
Type:           file
Capacity:       64.00 GiB
Allocation:     196.00 KiB

---- ----
vmname [Edwalafia]
----
volpool [data1]
volname [Edwalafia-data1-02.qcow]
Vol Edwalafia-data1-02.qcow created

Name:           Edwalafia-data1-02.qcow
Type:           file
Capacity:       64.00 GiB
Allocation:     196.00 KiB

----
volpool [data2]
volname [Edwalafia-data2-02.qcow]
Vol Edwalafia-data2-02.qcow created

Name:           Edwalafia-data2-02.qcow
Type:           file
Capacity:       64.00 GiB
Allocation:     196.00 KiB

---- ----
vmname [Onoza]
----
volpool [data1]
volname [Onoza-data1-02.qcow]
Vol Onoza-data1-02.qcow created

Name:           Onoza-data1-02.qcow
Type:           file
Capacity:       64.00 GiB
Allocation:     196.00 KiB

----
volpool [data2]
volname [Onoza-data2-02.qcow]
Vol Onoza-data2-02.qcow created

Name:           Onoza-data2-02.qcow
Type:           file
Capacity:       64.00 GiB
Allocation:     196.00 KiB
--STOP--


# -----------------------------------------------------
# Attach the new volume to each Kafka node.
#[user@trop03]


    for vmname in ${kfnames[@]}
        do
            echo "---- ----"
            echo "vmname [${vmname}]"
            for volpool in ${volpools[@]}
                do
                    echo "----"
                    volname=${vmname:?}-${volpool:?}-${volnum:?}.qcow
                    echo "volpool [${volpool}]"
                    echo "volname [${volname}]"

                    volpath=$(
                        virsh \
                            --connect "${connection:?}" \
                            vol-path \
                                --pool "${volpool:?}" \
                                "${volname:?}"
                        )

                    voldev=${voldevs[${volpool:?}]}
                    echo "voldev  [${voldev}]"
                    echo "volpath [${volpath}]"

                    virsh \
                        --connect "${connection:?}" \
                        attach-disk \
                            ${vmname:?}   \
                            ${volpath:?}  \
                            ${voldev:?}   \
                            --driver qemu  \
                            --subdriver qcow2

                done
        done


--START--
---- ----
vmname [Stedigo]
----
volpool [data1]
volname [Stedigo-data1-02.qcow]
voldev  [vde]
volpath [/data1/libvirt/images/data1/Stedigo-data1-02.qcow]
Disk attached successfully

----
volpool [data2]
volname [Stedigo-data2-02.qcow]
voldev  [vdf]
volpath [/data2/libvirt/images/data2/Stedigo-data2-02.qcow]
Disk attached successfully

---- ----
vmname [Angece]
----
volpool [data1]
volname [Angece-data1-02.qcow]
voldev  [vde]
volpath [/data1/libvirt/images/data1/Angece-data1-02.qcow]
Disk attached successfully

----
volpool [data2]
volname [Angece-data2-02.qcow]
voldev  [vdf]
volpath [/data2/libvirt/images/data2/Angece-data2-02.qcow]
Disk attached successfully

---- ----
vmname [Edwalafia]
----
volpool [data1]
volname [Edwalafia-data1-02.qcow]
voldev  [vde]
volpath [/data1/libvirt/images/data1/Edwalafia-data1-02.qcow]
Disk attached successfully

----
volpool [data2]
volname [Edwalafia-data2-02.qcow]
voldev  [vdf]
volpath [/data2/libvirt/images/data2/Edwalafia-data2-02.qcow]
Disk attached successfully

---- ----
vmname [Onoza]
----
volpool [data1]
volname [Onoza-data1-02.qcow]
voldev  [vde]
volpath [/data1/libvirt/images/data1/Onoza-data1-02.qcow]
Disk attached successfully

----
volpool [data2]
volname [Onoza-data2-02.qcow]
voldev  [vdf]
volpath [/data2/libvirt/images/data2/Onoza-data2-02.qcow]
Disk attached successfully
--STOP--


#---------------------------------------------------------------------
# Create a script to mount a volume.
#[user@virtual]

cat > /tmp/volume-mount.sh << 'EOSH'

echo "---- ----"
echo "hostname [$(hostname)]"
echo "devpath  [${devpath:?}]"
echo "mntpath  [${mntpath:?}]"

#---------------------------------------------------------------------
# Create a filesystem on the new device.

    sudo \
        mkfs.btrfs \
            --force \
            ${devpath:?}

#---------------------------------------------------------------------
# Create our mount point.

    sudo mkdir -p "${mntpath:?}"
    sudo touch "${mntpath:?}/mount-failed"

#---------------------------------------------------------------------
# Add the volume to our FileSystemTABle.
# https://www.howtoforge.com/reducing-disk-io-by-mounting-partitions-with-noatime

    devuuid=$(
        lsblk --noheadings --output UUID "${devpath:?}"
        )

sudo tee -a /etc/fstab << EOTAB
UUID=${devuuid:?} ${mntpath:?}    btrfs    defaults,noatime    0  0
EOTAB

#---------------------------------------------------------------------
# Mount the new volume.

    sudo \
        mount "${mntpath:?}"

#---------------------------------------------------------------------
# Check the new volume.

    df -h "${mntpath:?}"
    ls -l "${mntpath:?}"

EOSH

# -----------------------------------------------------
# Login and mount each of the new volumes.
#[user@trop03]

    for vmname in ${kfnames[@]}
        do
            for volpool in ${volpools[@]}
                do
                    devpath=/dev/${voldevs[${volpool}]}
                    mntpath=${volmnts[${volpool}]}
                    echo "---- ----"
                    echo "vmname  [${vmname}]"
                    echo "devpath [${devpath}]"
                    echo "mntpath [${mntpath}]"

                    echo "
                        export devpath=${devpath:?}
                        export mntpath=${mntpath:?}
                    " \
                    | cat - /tmp/volume-mount.sh \
                    | ssh \
                        ${sshopts[*]} \
                        ${sshuser:?}@${vmname:?}
                done
        done

--START--
---- ----
vmname  [Stedigo]
devpath [/dev/vde]
mntpath [/data1-02]
---- ----
hostname [Stedigo]
devpath  [/dev/vde]
mntpath  [/data1-02]
btrfs-progs v4.17.1
See http://btrfs.wiki.kernel.org for more information.

Label:              (null)
UUID:               55e5fcb2-c24a-4a21-8914-7843ac5596a9
Node size:          16384
Sector size:        4096
Filesystem size:    64.00GiB
Block group profiles:
  Data:             single            8.00MiB
  Metadata:         DUP               1.00GiB
  System:           DUP               8.00MiB
SSD detected:       no
Incompat features:  extref, skinny-metadata
Number of devices:  1
Devices:
   ID        SIZE  PATH
    1    64.00GiB  /dev/vde

UUID=55e5fcb2-c24a-4a21-8914-7843ac5596a9 /data1-02    btrfs    defaults,noatime    0  0
Filesystem      Size  Used Avail Use% Mounted on
/dev/vde         64G   17M   62G   1% /data1-02
total 0
---- ----
vmname  [Stedigo]
devpath [/dev/vdf]
mntpath [/data2-02]
---- ----
hostname [Stedigo]
devpath  [/dev/vdf]
mntpath  [/data2-02]
btrfs-progs v4.17.1
See http://btrfs.wiki.kernel.org for more information.

Label:              (null)
UUID:               b4d70a33-7af9-4762-b2a3-9c0c8c587bf4
Node size:          16384
Sector size:        4096
Filesystem size:    64.00GiB
Block group profiles:
  Data:             single            8.00MiB
  Metadata:         DUP               1.00GiB
  System:           DUP               8.00MiB
SSD detected:       no
Incompat features:  extref, skinny-metadata
Number of devices:  1
Devices:
   ID        SIZE  PATH
    1    64.00GiB  /dev/vdf

UUID=b4d70a33-7af9-4762-b2a3-9c0c8c587bf4 /data2-02    btrfs    defaults,noatime    0  0
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdf         64G   17M   62G   1% /data2-02
total 0
---- ----
vmname  [Angece]
devpath [/dev/vde]
mntpath [/data1-02]
---- ----
hostname [Angece]
devpath  [/dev/vde]
mntpath  [/data1-02]
btrfs-progs v4.17.1
See http://btrfs.wiki.kernel.org for more information.

Label:              (null)
UUID:               c553c0e4-b693-467a-ae4a-c594cc4d7afa
Node size:          16384
Sector size:        4096
Filesystem size:    64.00GiB
Block group profiles:
  Data:             single            8.00MiB
  Metadata:         DUP               1.00GiB
  System:           DUP               8.00MiB
SSD detected:       no
Incompat features:  extref, skinny-metadata
Number of devices:  1
Devices:
   ID        SIZE  PATH
    1    64.00GiB  /dev/vde

UUID=c553c0e4-b693-467a-ae4a-c594cc4d7afa /data1-02    btrfs    defaults,noatime    0  0
Filesystem      Size  Used Avail Use% Mounted on
/dev/vde         64G   17M   62G   1% /data1-02
total 0
---- ----
vmname  [Angece]
devpath [/dev/vdf]
mntpath [/data2-02]
---- ----
hostname [Angece]
devpath  [/dev/vdf]
mntpath  [/data2-02]
btrfs-progs v4.17.1
See http://btrfs.wiki.kernel.org for more information.

Label:              (null)
UUID:               e3a32ee7-c334-4346-820c-707e46c1d3d8
Node size:          16384
Sector size:        4096
Filesystem size:    64.00GiB
Block group profiles:
  Data:             single            8.00MiB
  Metadata:         DUP               1.00GiB
  System:           DUP               8.00MiB
SSD detected:       no
Incompat features:  extref, skinny-metadata
Number of devices:  1
Devices:
   ID        SIZE  PATH
    1    64.00GiB  /dev/vdf

UUID=e3a32ee7-c334-4346-820c-707e46c1d3d8 /data2-02    btrfs    defaults,noatime    0  0
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdf         64G   17M   62G   1% /data2-02
total 0
---- ----
vmname  [Edwalafia]
devpath [/dev/vde]
mntpath [/data1-02]
---- ----
hostname [Edwalafia]
devpath  [/dev/vde]
mntpath  [/data1-02]
btrfs-progs v4.17.1
See http://btrfs.wiki.kernel.org for more information.

Label:              (null)
UUID:               a921ae6f-02b0-4da3-88dd-bf5252cfcfdb
Node size:          16384
Sector size:        4096
Filesystem size:    64.00GiB
Block group profiles:
  Data:             single            8.00MiB
  Metadata:         DUP               1.00GiB
  System:           DUP               8.00MiB
SSD detected:       no
Incompat features:  extref, skinny-metadata
Number of devices:  1
Devices:
   ID        SIZE  PATH
    1    64.00GiB  /dev/vde

UUID=a921ae6f-02b0-4da3-88dd-bf5252cfcfdb /data1-02    btrfs    defaults,noatime    0  0
Filesystem      Size  Used Avail Use% Mounted on
/dev/vde         64G   17M   62G   1% /data1-02
total 0
---- ----
vmname  [Edwalafia]
devpath [/dev/vdf]
mntpath [/data2-02]
---- ----
hostname [Edwalafia]
devpath  [/dev/vdf]
mntpath  [/data2-02]
btrfs-progs v4.17.1
See http://btrfs.wiki.kernel.org for more information.

Label:              (null)
UUID:               ce19d30f-2583-4106-b093-e67127beb96d
Node size:          16384
Sector size:        4096
Filesystem size:    64.00GiB
Block group profiles:
  Data:             single            8.00MiB
  Metadata:         DUP               1.00GiB
  System:           DUP               8.00MiB
SSD detected:       no
Incompat features:  extref, skinny-metadata
Number of devices:  1
Devices:
   ID        SIZE  PATH
    1    64.00GiB  /dev/vdf

UUID=ce19d30f-2583-4106-b093-e67127beb96d /data2-02    btrfs    defaults,noatime    0  0
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdf         64G   17M   62G   1% /data2-02
total 0
---- ----
vmname  [Onoza]
devpath [/dev/vde]
mntpath [/data1-02]
---- ----
hostname [Onoza]
devpath  [/dev/vde]
mntpath  [/data1-02]
btrfs-progs v4.17.1
See http://btrfs.wiki.kernel.org for more information.

Label:              (null)
UUID:               dde98c24-9112-45b4-8ca6-6d6ac85ca9b0
Node size:          16384
Sector size:        4096
Filesystem size:    64.00GiB
Block group profiles:
  Data:             single            8.00MiB
  Metadata:         DUP               1.00GiB
  System:           DUP               8.00MiB
SSD detected:       no
Incompat features:  extref, skinny-metadata
Number of devices:  1
Devices:
   ID        SIZE  PATH
    1    64.00GiB  /dev/vde

UUID=dde98c24-9112-45b4-8ca6-6d6ac85ca9b0 /data1-02    btrfs    defaults,noatime    0  0
Filesystem      Size  Used Avail Use% Mounted on
/dev/vde         64G   17M   62G   1% /data1-02
total 0
---- ----
vmname  [Onoza]
devpath [/dev/vdf]
mntpath [/data2-02]
---- ----
hostname [Onoza]
devpath  [/dev/vdf]
mntpath  [/data2-02]
btrfs-progs v4.17.1
See http://btrfs.wiki.kernel.org for more information.

Label:              (null)
UUID:               ceba1807-350d-44be-9640-b01c57bdc749
Node size:          16384
Sector size:        4096
Filesystem size:    64.00GiB
Block group profiles:
  Data:             single            8.00MiB
  Metadata:         DUP               1.00GiB
  System:           DUP               8.00MiB
SSD detected:       no
Incompat features:  extref, skinny-metadata
Number of devices:  1
Devices:
   ID        SIZE  PATH
    1    64.00GiB  /dev/vdf

UUID=ceba1807-350d-44be-9640-b01c57bdc749 /data2-02    btrfs    defaults,noatime    0  0
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdf         64G   17M   62G   1% /data2-02
total 0
--STOP--


# -----------------------------------------------------
# Check the available space on each Kafka node.
#[user@trop03]

    for vmname in ${kfnames[@]}
        do
            echo "---- ----"
            echo "vmname [${vmname:?}]"
            ssh \
                ${scpopts[*]} \
                ${sshuser:?}@${vmname:?} \
                "
                df -h | grep '^/dev/' | sort
                "
        done

--START--
---- ----
vmname [Stedigo]
/dev/vda1       240M  118M  106M  53% /boot
/dev/vda3       6.8G  2.4G  3.9G  39% /
/dev/vdc         32G   31G   48K 100% /data1-01
/dev/vdd         32G   31G   56K 100% /data2-01
/dev/vde         64G   17M   62G   1% /data1-02
/dev/vdf         64G   17M   62G   1% /data2-02
---- ----
vmname [Angece]
/dev/vda1       240M  118M  106M  53% /boot
/dev/vda3       6.8G  2.4G  3.9G  39% /
/dev/vdc         32G   31G   20K 100% /data1-01
/dev/vdd         32G   31G   12K 100% /data2-01
/dev/vde         64G   17M   62G   1% /data1-02
/dev/vdf         64G   17M   62G   1% /data2-02
---- ----
vmname [Edwalafia]
/dev/vda1       240M  118M  106M  53% /boot
/dev/vda3       6.8G  2.4G  3.9G  39% /
/dev/vdc         32G   31G  1.3M 100% /data1-01
/dev/vdd         32G   31G   44K 100% /data2-01
/dev/vde         64G   17M   62G   1% /data1-02
/dev/vdf         64G   17M   62G   1% /data2-02
---- ----
vmname [Onoza]
/dev/vda1       240M  118M  106M  53% /boot
/dev/vda3       6.8G  2.4G  3.9G  39% /
/dev/vdc         32G   31G   28K 100% /data1-01
/dev/vdd         32G   31G   16K 100% /data2-01
/dev/vde         64G   17M   62G   1% /data1-02
/dev/vdf         64G   17M   62G   1% /data2-02
--STOP--

# -----------------------------------------------------
# Update the Kafka compose ENV file.
#[user@trop03]

    newvols=/data1-02,/data2-02

    for vmname in ${kfnames[@]}
        do
            echo "---- ----"
            echo "vmname [${vmname:?}]"
            ssh \
                ${scpopts[*]} \
                ${sshuser:?}@${vmname:?} \
                    "
                    sed -i '
                        s|KAFKA_LOG_DIRS=\(.*\)|KAFKA_LOG_DIRS=\1,${newvols}|
                        ' kafka.env

                    sed -n '
                        /^KAFKA_LOG_DIRS/ p
                        ' kafka.env
                    "
        done

--START--
---- ----
vmname [Stedigo]
KAFKA_LOG_DIRS=/data1-01,/data2-01,/data1-02,/data2-02
---- ----
vmname [Angece]
KAFKA_LOG_DIRS=/data1-01,/data2-01,/data1-02,/data2-02
---- ----
vmname [Edwalafia]
KAFKA_LOG_DIRS=/data1-01,/data2-01,/data1-02,/data2-02
---- ----
vmname [Onoza]
KAFKA_LOG_DIRS=/data1-01,/data2-01,/data1-02,/data2-02
--STOP--

# -----------------------------------------------------
# Start Kafka on each node.
#[user@trop03]

    for vmname in ${kfnames[@]}
        do
            echo "---- ----"
            ssh \
                ${scpopts[*]} \
                ${sshuser:?}@${vmname:?} \
                "
                hostname
                docker-compose \
                    --file kafka.yml \
                    up -d
                "
        done

--START--
---- ----
Stedigo
Creating network "stevedore_default" with the default driver
Creating stevedore_emily_1 ... done
---- ----
Angece
Creating network "stevedore_default" with the default driver
Creating stevedore_emily_1 ... done
---- ----
Edwalafia
Creating network "stevedore_default" with the default driver
Creating stevedore_emily_1 ... done
---- ----
Onoza
Creating network "stevedore_default" with the default driver
Creating stevedore_emily_1 ... done
--STOP--

# -----------------------------------------------------
# Login and tail the logs (separate terminals).
#[user@trop03]

    ssh trop03

        ssh Edwalafia
        ssh Onoza
        ssh Angece
        ssh Stedigo

            docker logs -f stevedore_emily_1


--START--
[2018-12-23 14:22:04,946] INFO [Log partition=ztf_20181205_programid1-12, dir=/data1-01] Completed load of log with 1 segments, log start offset 0 and log end offset 10622 in 48339 ms (kafka.log.Log)
[2018-12-23 14:22:04,946] INFO [Log partition=ztf_20181205_programid1-8, dir=/data2-01] Completed load of log with 1 segments, log start offset 0 and log end offset 10622 in 47837 ms (kafka.log.Log)
[2018-12-23 14:22:04,953] WARN [Log partition=ztf_20181205_programid1-0, dir=/data2-01] Found a corrupted index file corresponding to log file /data2-01/ztf_20181205_programid1-0/00000000000000000000.log due to Corrupt index found, index file (/data2-01/ztf_20181205_programid1-0/00000000000000000000.index) has non-zero size but the last offset is 0 which is no greater than the base offset 0.}, recovering segment and rebuilding index files... (kafka.log.Log)
[2018-12-23 14:22:04,953] WARN [Log partition=ztf_20181205_programid1-4, dir=/data1-01] Found a corrupted index file corresponding to log file /data1-01/ztf_20181205_programid1-4/00000000000000000000.log due to Corrupt index found, index file (/data1-01/ztf_20181205_programid1-4/00000000000000000000.index) has non-zero size but the last offset is 0 which is no greater than the base offset 0.}, recovering segment and rebuilding index files... (kafka.log.Log)
....
....
[2018-12-23 15:05:23,029] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions ztf_20181215_programid1-7 (kafka.server.ReplicaFetcherManager)
[2018-12-23 15:05:23,029] INFO [Partition ztf_20181215_programid1-7 broker=3] ztf_20181215_programid1-7 starts at Leader Epoch 4 from offset 642. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2018-12-23 15:05:23,029] TRACE [Broker id=3] Stopped fetchers as part of become-leader request from controller 2 epoch 3 with correlation id 178 for partition ztf_20181215_programid1-7 (last update controller epoch 3) (state.change.logger)
[2018-12-23 15:05:23,029] TRACE [Broker id=3] Completed LeaderAndIsr request correlationId 178 from controller 2 epoch 3 for the become-leader transition for partition ztf_20181215_programid1-7 (state.change.logger)
[2018-12-23 15:05:23,030] INFO [ReplicaAlterLogDirsManager on broker 3] Added fetcher for partitions List() (kafka.server.ReplicaAlterLogDirsManager)
[2018-12-23 15:05:23,031] TRACE [Broker id=3] Cached leader info PartitionState(controllerEpoch=3, leader=3, leaderEpoch=4, isr=[1, 3, 2], zkVersion=6, replicas=[3, 1, 2], offlineReplicas=[]) for partition ztf_20181215_programid1-7 in response to UpdateMetadata request sent by controller 2 epoch 3 with correlation id 179 (state.change.logger)
--STOP--

--START--
[2018-12-23 14:22:06,780] INFO [Log partition=ztf_20181205_programid1-9, dir=/data2-01] Recovering unflushed segment 0 (kafka.log.Log)
[2018-12-23 14:22:08,648] INFO [ProducerStateManager partition=ztf_20181205_programid1-9] Writing producer snapshot at offset 10622 (kafka.log.ProducerStateManager)
[2018-12-23 14:22:08,651] INFO [Log partition=ztf_20181205_programid1-9, dir=/data2-01] Loading producer state from offset 10622 with message format version 2 (kafka.log.Log)
[2018-12-23 14:22:08,652] INFO [ProducerStateManager partition=ztf_20181205_programid1-9] Loading producer state from snapshot file '/data2-01/ztf_20181205_programid1-9/00000000000000010622.snapshot' (kafka.log.ProducerStateManager)
[2018-12-23 14:22:08,652] INFO [Log partition=ztf_20181205_programid1-9, dir=/data2-01] Completed load of log with 1 segments, log start offset 0 and log end offset 10622 in 49092 ms (kafka.log.Log)
[2018-12-23 14:22:08,659] WARN [Log partition=ztf_20181205_programid1-1, dir=/data2-01] Found a corrupted index file corresponding to log file /data2-01/ztf_20181205_programid1-1/00000000000000000000.log due to Corrupt index found, index file (/data2-01/ztf_20181205_programid1-1/00000000000000000000.index) has non-zero size but the last offset is 0 which is no greater than the base offset 0.}, recovering segment and rebuilding index files... (kafka.log.Log)
....
....
[2018-12-23 15:05:23,299] INFO [Log partition=ztf_20181209_programid1-13, dir=/data2-01] Truncating to 4205 has no effect as the largest offset in the log is 4204 (kafka.log.Log)
[2018-12-23 15:05:23,300] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 10622 >= the follower's log end offset 10622 in ztf_20181205_programid1-8. No truncation needed. (kafka.server.ReplicaFetcherThread)
[2018-12-23 15:05:23,300] INFO [Log partition=ztf_20181205_programid1-8, dir=/data1-01] Truncating to 10622 has no effect as the largest offset in the log is 10621 (kafka.log.Log)
[2018-12-23 15:05:23,300] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 10622 >= the follower's log end offset 10622 in ztf_20181205_programid1-0. No truncation needed. (kafka.server.ReplicaFetcherThread)
[2018-12-23 15:05:23,300] INFO [Log partition=ztf_20181205_programid1-0, dir=/data2-01] Truncating to 10622 has no effect as the largest offset in the log is 10621 (kafka.log.Log)
[2018-12-23 15:05:23,300] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 14906 >= the follower's log end offset 14906 in ztf_20181214_programid1-10. No truncation needed. (kafka.server.ReplicaFetcherThread)
[2018-12-23 15:05:23,300] INFO [Log partition=ztf_20181214_programid1-10, dir=/data1-01] Truncating to 14906 has no effect as the largest offset in the log is 14905 (kafka.log.Log)
[2018-12-23 15:05:23,300] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 15722 >= the follower's log end offset 15722 in ztf_20181217_programid1-0. No truncation needed. (kafka.server.ReplicaFetcherThread)
[2018-12-23 15:05:23,300] INFO [Log partition=ztf_20181217_programid1-0, dir=/data2-01] Truncating to 15722 has no effect as the largest offset in the log is 15721 (kafka.log.Log)
[2018-12-23 15:05:23,300] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 8649 >= the follower's log end offset 8649 in ztf_20181216_programid1-11. No truncation needed. (kafka.server.ReplicaFetcherThread)
[2018-12-23 15:05:23,300] INFO [Log partition=ztf_20181216_programid1-11, dir=/data2-01] Truncating to 8649 has no effect as the largest offset in the log is 8648 (kafka.log.Log)
--STOP--

--START--
[2018-12-23 14:22:01,917] INFO [ProducerStateManager partition=ztf_20181205_programid1-15] Writing producer snapshot at offset 10622 (kafka.log.ProducerStateManager)
[2018-12-23 14:22:01,920] INFO [Log partition=ztf_20181205_programid1-15, dir=/data1-01] Loading producer state from offset 10622 with message format version 2 (kafka.log.Log)
[2018-12-23 14:22:01,921] INFO [ProducerStateManager partition=ztf_20181205_programid1-15] Loading producer state from snapshot file '/data1-01/ztf_20181205_programid1-15/00000000000000010622.snapshot' (kafka.log.ProducerStateManager)
[2018-12-23 14:22:01,921] INFO [Log partition=ztf_20181205_programid1-15, dir=/data1-01] Completed load of log with 1 segments, log start offset 0 and log end offset 10622 in 47748 ms (kafka.log.Log)
[2018-12-23 14:22:01,930] WARN [Log partition=ztf_20181205_programid1-7, dir=/data1-01] Found a corrupted index file corresponding to log file /data1-01/ztf_20181205_programid1-7/00000000000000000000.log due to Corrupt index found, index file (/data1-01/ztf_20181205_programid1-7/00000000000000000000.index) has non-zero size but the last offset is 0 which is no greater than the base offset 0.}, recovering segment and rebuilding index files... (kafka.log.Log)
....
....
[2018-12-23 15:10:23,031] DEBUG [Controller id=2] Topics not in preferred replica for broker 2 Map() (kafka.controller.KafkaController)
[2018-12-23 15:10:23,031] TRACE [Controller id=2] Leader imbalance ratio for broker 2 is 0.0 (kafka.controller.KafkaController)
[2018-12-23 15:10:23,031] DEBUG [Controller id=2] Topics not in preferred replica for broker 4 Map() (kafka.controller.KafkaController)
[2018-12-23 15:10:23,031] TRACE [Controller id=2] Leader imbalance ratio for broker 4 is 0.0 (kafka.controller.KafkaController)
[2018-12-23 15:10:23,031] DEBUG [Controller id=2] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
[2018-12-23 15:10:23,031] TRACE [Controller id=2] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
[2018-12-23 15:10:23,032] DEBUG [Controller id=2] Topics not in preferred replica for broker 3 Map() (kafka.controller.KafkaController)
[2018-12-23 15:10:23,032] TRACE [Controller id=2] Leader imbalance ratio for broker 3 is 0.0 (kafka.controller.KafkaController)
--STOP--

--START--
[2018-12-23 14:22:46,026] INFO [ProducerStateManager partition=ztf_20181205_programid1-10] Writing producer snapshot at offset 10622 (kafka.log.ProducerStateManager)
[2018-12-23 14:22:46,028] INFO [Log partition=ztf_20181205_programid1-10, dir=/data2-01] Loading producer state from offset 10622 with message format version 2 (kafka.log.Log)
[2018-12-23 14:22:46,030] INFO [ProducerStateManager partition=ztf_20181205_programid1-10] Loading producer state from snapshot file '/data2-01/ztf_20181205_programid1-10/00000000000000010622.snapshot' (kafka.log.ProducerStateManager)
[2018-12-23 14:22:46,030] INFO [Log partition=ztf_20181205_programid1-10, dir=/data2-01] Completed load of log with 1 segments, log start offset 0 and log end offset 10622 in 48428 ms (kafka.log.Log)
[2018-12-23 14:22:46,146] WARN [Log partition=ztf_20181205_programid1-11, dir=/data2-01] Found a corrupted index file corresponding to log file /data2-01/ztf_20181205_programid1-11/00000000000000000000.log due to Corrupt index found, index file (/data2-01/ztf_20181205_programid1-11/00000000000000000000.index) has non-zero size but the last offset is 0 which is no greater than the base offset 0.}, recovering segment and rebuilding index files... (kafka.log.Log)
....
....
[2018-12-23 15:05:23,298] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 6744 >= the follower's log end offset 6744 in ztf_20181210_programid1-6. No truncation needed. (kafka.server.ReplicaFetcherThread)
[2018-12-23 15:05:23,299] INFO [Log partition=ztf_20181210_programid1-6, dir=/data2-01] Truncating to 6744 has no effect as the largest offset in the log is 6743 (kafka.log.Log)
[2018-12-23 15:05:23,299] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 15722 >= the follower's log end offset 15722 in ztf_20181217_programid1-0. No truncation needed. (kafka.server.ReplicaFetcherThread)
[2018-12-23 15:05:23,300] INFO [Log partition=ztf_20181217_programid1-0, dir=/data1-01] Truncating to 15722 has no effect as the largest offset in the log is 15721 (kafka.log.Log)
[2018-12-23 15:05:23,300] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on follower's leader epoch, leader replied with an offset 642 >= the follower's log end offset 642 in ztf_20181215_programid1-7. No truncation needed. (kafka.server.ReplicaFetcherThread)
[2018-12-23 15:05:23,300] INFO [Log partition=ztf_20181215_programid1-7, dir=/data1-01] Truncating to 642 has no effect as the largest offset in the log is 641 (kafka.log.Log)
--STOP--


# -----------------------------------------------------
# Check the available topics in our Kafka system.
# https://docs.confluent.io/current/app-development/kafkacat-usage.html
# https://github.com/edenhill/kafkacat
#[user@trop03]

    devnode=Rusaldez

    ztfconnect=public.alerts.ztf.uw.edu:9092

    roetemp=${kfnames[*]}
    roeconnect=${roetemp// /:9092,}:9092
    roegroupid=ztf-mirror.roe.ac.uk

    ssh \
        ${sshopts[*]} \
        ${sshuser:?}@${devnode:?} \
        "
        docker run \
            --rm \
            phymatopus/kafkacat:latest \
                -b "${roeconnect:?}" \
                -L \
                -J \
        | jq -r '.topics[] | select(.topic | startswith(\"__\") | not)  | .topic' \
        | sort
        " \
    | tee /tmp/topiclist

--START--
ztf_20181205_programid1
ztf_20181209_programid1
ztf_20181210_programid1
ztf_20181212_programid1
ztf_20181213_programid1
ztf_20181214_programid1
ztf_20181215_programid1
ztf_20181216_programid1
ztf_20181217_programid1
--STOP--


# -----------------------------------------------------
# Check the topics offsets in our Kafka system.
#[user@trop03]

    brokers=${roeconnect:?}

    for topicid in $(cat /tmp/topiclist)
    do
        echo "--------------------"
        echo "Topic [${topicid:?}]"

        ssh \
            ${sshopts[*]} \
            ${sshuser:?}@${devnode:?} \
            "
            docker run --rm phymatopus/kafka-core \
                bin/kafka-run-class.sh kafka.tools.GetOffsetShell \
                    --broker-list "${brokers:?}" \
                    --topic "${topicid:?}" \
                    --time -1
            docker run --rm phymatopus/kafka-core \
                bin/kafka-run-class.sh kafka.tools.GetOffsetShell \
                    --broker-list "${brokers:?}" \
                    --topic "${topicid:?}" \
                    --time -2
            " \
        | sort

    done

--START--
--------------------
Topic [ztf_20181205_programid1]
ztf_20181205_programid1:0:0
ztf_20181205_programid1:0:10622
ztf_20181205_programid1:1:0
ztf_20181205_programid1:10:0
ztf_20181205_programid1:10:10622
ztf_20181205_programid1:11:0
ztf_20181205_programid1:1:10623
ztf_20181205_programid1:11:10622
ztf_20181205_programid1:12:0
ztf_20181205_programid1:12:10622
ztf_20181205_programid1:13:0
ztf_20181205_programid1:13:10622
ztf_20181205_programid1:14:0
ztf_20181205_programid1:14:10622
ztf_20181205_programid1:15:0
ztf_20181205_programid1:15:10622
ztf_20181205_programid1:2:0
ztf_20181205_programid1:2:10622
ztf_20181205_programid1:3:0
ztf_20181205_programid1:3:10622
ztf_20181205_programid1:4:0
ztf_20181205_programid1:4:10622
ztf_20181205_programid1:5:0
ztf_20181205_programid1:5:10622
ztf_20181205_programid1:6:0
ztf_20181205_programid1:6:10622
ztf_20181205_programid1:7:0
ztf_20181205_programid1:7:10622
ztf_20181205_programid1:8:0
ztf_20181205_programid1:8:10622
ztf_20181205_programid1:9:0
ztf_20181205_programid1:9:10622
--------------------
Topic [ztf_20181209_programid1]
ztf_20181209_programid1:0:0
ztf_20181209_programid1:0:4206
ztf_20181209_programid1:1:0
ztf_20181209_programid1:10:0
ztf_20181209_programid1:10:4205
ztf_20181209_programid1:11:0
ztf_20181209_programid1:11:4206
ztf_20181209_programid1:12:0
ztf_20181209_programid1:12:4206
ztf_20181209_programid1:13:0
ztf_20181209_programid1:13:4205
ztf_20181209_programid1:14:0
ztf_20181209_programid1:1:4206
ztf_20181209_programid1:14:4205
ztf_20181209_programid1:15:0
ztf_20181209_programid1:15:4206
ztf_20181209_programid1:2:0
ztf_20181209_programid1:2:4206
ztf_20181209_programid1:3:0
ztf_20181209_programid1:3:4206
ztf_20181209_programid1:4:0
ztf_20181209_programid1:4:4205
ztf_20181209_programid1:5:0
ztf_20181209_programid1:5:4205
ztf_20181209_programid1:6:0
ztf_20181209_programid1:6:4206
ztf_20181209_programid1:7:0
ztf_20181209_programid1:7:4205
ztf_20181209_programid1:8:0
ztf_20181209_programid1:8:4206
ztf_20181209_programid1:9:0
ztf_20181209_programid1:9:4205
--------------------
Topic [ztf_20181210_programid1]
ztf_20181210_programid1:0:0
ztf_20181210_programid1:0:6744
ztf_20181210_programid1:1:0
ztf_20181210_programid1:10:0
ztf_20181210_programid1:10:6744
ztf_20181210_programid1:11:0
ztf_20181210_programid1:11:6744
ztf_20181210_programid1:12:0
ztf_20181210_programid1:12:6744
ztf_20181210_programid1:13:0
ztf_20181210_programid1:13:6744
ztf_20181210_programid1:14:0
ztf_20181210_programid1:14:6742
ztf_20181210_programid1:15:0
ztf_20181210_programid1:15:6744
ztf_20181210_programid1:1:6744
ztf_20181210_programid1:2:0
ztf_20181210_programid1:2:6743
ztf_20181210_programid1:3:0
ztf_20181210_programid1:3:6744
ztf_20181210_programid1:4:0
ztf_20181210_programid1:4:6744
ztf_20181210_programid1:5:0
ztf_20181210_programid1:5:6742
ztf_20181210_programid1:6:0
ztf_20181210_programid1:6:6744
ztf_20181210_programid1:7:0
ztf_20181210_programid1:7:6744
ztf_20181210_programid1:8:0
ztf_20181210_programid1:8:6744
ztf_20181210_programid1:9:0
ztf_20181210_programid1:9:6744
--------------------
Topic [ztf_20181212_programid1]
ztf_20181212_programid1:0:0
ztf_20181212_programid1:0:9896
ztf_20181212_programid1:1:0
ztf_20181212_programid1:10:0
ztf_20181212_programid1:10:9896
ztf_20181212_programid1:11:0
ztf_20181212_programid1:11:9896
ztf_20181212_programid1:12:0
ztf_20181212_programid1:12:9896
ztf_20181212_programid1:13:0
ztf_20181212_programid1:13:9897
ztf_20181212_programid1:14:0
ztf_20181212_programid1:14:9896
ztf_20181212_programid1:15:0
ztf_20181212_programid1:15:9896
ztf_20181212_programid1:1:9896
ztf_20181212_programid1:2:0
ztf_20181212_programid1:2:9897
ztf_20181212_programid1:3:0
ztf_20181212_programid1:3:9896
ztf_20181212_programid1:4:0
ztf_20181212_programid1:4:9897
ztf_20181212_programid1:5:0
ztf_20181212_programid1:5:9897
ztf_20181212_programid1:6:0
ztf_20181212_programid1:6:9896
ztf_20181212_programid1:7:0
ztf_20181212_programid1:7:9897
ztf_20181212_programid1:8:0
ztf_20181212_programid1:8:9896
ztf_20181212_programid1:9:0
ztf_20181212_programid1:9:9896
--------------------
Topic [ztf_20181213_programid1]
ztf_20181213_programid1:0:0
ztf_20181213_programid1:0:7572
ztf_20181213_programid1:1:0
ztf_20181213_programid1:10:0
ztf_20181213_programid1:10:7574
ztf_20181213_programid1:11:0
ztf_20181213_programid1:11:7572
ztf_20181213_programid1:12:0
ztf_20181213_programid1:12:7572
ztf_20181213_programid1:13:0
ztf_20181213_programid1:13:7574
ztf_20181213_programid1:14:0
ztf_20181213_programid1:14:7574
ztf_20181213_programid1:15:0
ztf_20181213_programid1:15:7572
ztf_20181213_programid1:1:7574
ztf_20181213_programid1:2:0
ztf_20181213_programid1:2:7572
ztf_20181213_programid1:3:0
ztf_20181213_programid1:3:7573
ztf_20181213_programid1:4:0
ztf_20181213_programid1:4:7574
ztf_20181213_programid1:5:0
ztf_20181213_programid1:5:7574
ztf_20181213_programid1:6:0
ztf_20181213_programid1:6:7572
ztf_20181213_programid1:7:0
ztf_20181213_programid1:7:7574
ztf_20181213_programid1:8:0
ztf_20181213_programid1:8:7572
ztf_20181213_programid1:9:0
ztf_20181213_programid1:9:7574
--------------------
Topic [ztf_20181214_programid1]
ztf_20181214_programid1:0:0
ztf_20181214_programid1:0:14906
ztf_20181214_programid1:1:0
ztf_20181214_programid1:10:0
ztf_20181214_programid1:10:14906
ztf_20181214_programid1:11:0
ztf_20181214_programid1:11:14905
ztf_20181214_programid1:1:14906
ztf_20181214_programid1:12:0
ztf_20181214_programid1:12:14906
ztf_20181214_programid1:13:0
ztf_20181214_programid1:13:14905
ztf_20181214_programid1:14:0
ztf_20181214_programid1:14:14905
ztf_20181214_programid1:15:0
ztf_20181214_programid1:15:14906
ztf_20181214_programid1:2:0
ztf_20181214_programid1:2:14905
ztf_20181214_programid1:3:0
ztf_20181214_programid1:3:14906
ztf_20181214_programid1:4:0
ztf_20181214_programid1:4:14906
ztf_20181214_programid1:5:0
ztf_20181214_programid1:5:14904
ztf_20181214_programid1:6:0
ztf_20181214_programid1:6:14906
ztf_20181214_programid1:7:0
ztf_20181214_programid1:7:14906
ztf_20181214_programid1:8:0
ztf_20181214_programid1:8:14906
ztf_20181214_programid1:9:0
ztf_20181214_programid1:9:14906
--------------------
Topic [ztf_20181215_programid1]
ztf_20181215_programid1:0:0
ztf_20181215_programid1:0:641
ztf_20181215_programid1:1:0
ztf_20181215_programid1:10:0
ztf_20181215_programid1:10:642
ztf_20181215_programid1:11:0
ztf_20181215_programid1:11:640
ztf_20181215_programid1:12:0
ztf_20181215_programid1:12:642
ztf_20181215_programid1:13:0
ztf_20181215_programid1:13:642
ztf_20181215_programid1:14:0
ztf_20181215_programid1:14:641
ztf_20181215_programid1:15:0
ztf_20181215_programid1:15:642
ztf_20181215_programid1:1:642
ztf_20181215_programid1:2:0
ztf_20181215_programid1:2:640
ztf_20181215_programid1:3:0
ztf_20181215_programid1:3:642
ztf_20181215_programid1:4:0
ztf_20181215_programid1:4:642
ztf_20181215_programid1:5:0
ztf_20181215_programid1:5:640
ztf_20181215_programid1:6:0
ztf_20181215_programid1:6:641
ztf_20181215_programid1:7:0
ztf_20181215_programid1:7:642
ztf_20181215_programid1:8:0
ztf_20181215_programid1:8:640
ztf_20181215_programid1:9:0
ztf_20181215_programid1:9:642
--------------------
Topic [ztf_20181216_programid1]
ztf_20181216_programid1:0:0
ztf_20181216_programid1:0:8650
ztf_20181216_programid1:1:0
ztf_20181216_programid1:10:0
ztf_20181216_programid1:10:8650
ztf_20181216_programid1:11:0
ztf_20181216_programid1:11:8649
ztf_20181216_programid1:12:0
ztf_20181216_programid1:12:8650
ztf_20181216_programid1:13:0
ztf_20181216_programid1:13:8650
ztf_20181216_programid1:14:0
ztf_20181216_programid1:14:8650
ztf_20181216_programid1:15:0
ztf_20181216_programid1:15:8649
ztf_20181216_programid1:1:8650
ztf_20181216_programid1:2:0
ztf_20181216_programid1:2:8649
ztf_20181216_programid1:3:0
ztf_20181216_programid1:3:8650
ztf_20181216_programid1:4:0
ztf_20181216_programid1:4:8650
ztf_20181216_programid1:5:0
ztf_20181216_programid1:5:8650
ztf_20181216_programid1:6:0
ztf_20181216_programid1:6:8650
ztf_20181216_programid1:7:0
ztf_20181216_programid1:7:8650
ztf_20181216_programid1:8:0
ztf_20181216_programid1:8:8649
ztf_20181216_programid1:9:0
ztf_20181216_programid1:9:8650
--------------------
Topic [ztf_20181217_programid1]
ztf_20181217_programid1:0:0
ztf_20181217_programid1:0:15722
ztf_20181217_programid1:1:0
ztf_20181217_programid1:10:0
ztf_20181217_programid1:10:15723
ztf_20181217_programid1:11:0
ztf_20181217_programid1:11:15736
ztf_20181217_programid1:1:15727
ztf_20181217_programid1:12:0
ztf_20181217_programid1:12:15722
ztf_20181217_programid1:13:0
ztf_20181217_programid1:13:15725
ztf_20181217_programid1:14:0
ztf_20181217_programid1:14:15721
ztf_20181217_programid1:15:0
ztf_20181217_programid1:15:15740
ztf_20181217_programid1:2:0
ztf_20181217_programid1:2:15723
ztf_20181217_programid1:3:0
ztf_20181217_programid1:3:15736
ztf_20181217_programid1:4:0
ztf_20181217_programid1:4:15722
ztf_20181217_programid1:5:0
ztf_20181217_programid1:5:15724
ztf_20181217_programid1:6:0
ztf_20181217_programid1:6:15725
ztf_20181217_programid1:7:0
ztf_20181217_programid1:7:15739
ztf_20181217_programid1:8:0
ztf_20181217_programid1:8:15719
ztf_20181217_programid1:9:0
ztf_20181217_programid1:9:15726
--STOP--


# -----------------------------------------------------
# Update the topic and restart MirrorMaker on each node.
#[user@trop03]

    ztftopicid=ztf_20181218_programid1
    ztftopicid=ztf_20181219_programid1

    for vmname in ${mmnames[@]}
        do
            echo "---- ----"
            echo "vmname [${vmname:?}]"
            ssh \
                ${scpopts[*]} \
                ${sshuser:?}@${vmname:?} \
                "
                docker-compose \
                    --file mirror.yml \
                    down
                sed -i \"
                    s/^ztftopicid=.*/ztftopicid=${ztftopicid:?}/
                    \" mirror.env
                docker-compose \
                    --file mirror.yml \
                    up -d
                "
        done


--START--
---- ----
vmname [Afoaviel]
Stopping stevedore_tina_1 ... done
Removing stevedore_tina_1 ... done
Removing network stevedore_default
Creating network "stevedore_default" with the default driver
Creating stevedore_tina_1 ... done
---- ----
vmname [Rusaldez]
Stopping stevedore_tina_1 ... done
Removing stevedore_tina_1 ... done
Removing network stevedore_default
Creating network "stevedore_default" with the default driver
Creating stevedore_tina_1 ... done
--STOP--


    for vmname in ${mmnames[@]}
        do
            echo "---- ----"
            echo "vmname [${vmname:?}]"
            ssh \
                ${scpopts[*]} \
                ${sshuser:?}@${vmname:?} \
                "
                docker ps
                "
        done


--START--
---- ----
vmname [Afoaviel]
CONTAINER ID        IMAGE                   COMMAND                  CREATED             STATUS              PORTS               NAMES
31ec7e03f2fa        phymatopus/kafka-core   "bin/kafka-mirror-ma…"   40 seconds ago      Up 39 seconds                           stevedore_tina_1
---- ----
vmname [Rusaldez]
CONTAINER ID        IMAGE                   COMMAND                  CREATED             STATUS              PORTS               NAMES
222d07e87ee0        phymatopus/kafka-core   "bin/kafka-mirror-ma…"   36 seconds ago      Up 35 seconds                           stevedore_tina_1
--STOP--


# -----------------------------------------------------
# Check our client offsets in the ZTF broker.
#[user@trop03]

    devnode=Rusaldez

    ztfconnect=public.alerts.ztf.uw.edu:9092
    roegroupid=ztf-mirror.roe.ac.uk

    date ; \
    ssh \
        ${sshopts[*]} \
        ${sshuser:?}@${devnode:?} \
        "
        docker run --rm phymatopus/kafka-core \
            bin/kafka-consumer-groups.sh \
                --bootstrap-server "${ztfconnect:?}" \
                --describe \
                --group "${roegroupid:?}"
         " \
    | sort \
    ; date

--START--
Sun 23 Dec 16:24:36 GMT 2018
Note: This will not show information about old Zookeeper-based consumers.
Sun 23 Dec 16:24:42 GMT 2018
--STOP--


--START--
Sun 23 Dec 16:37:14 GMT 2018
TOPIC                   PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                 HOST            CLIENT-ID
ztf_20181219_programid1 0          1573            20858           19285           ztf-mirror.roe.ac.uk-0-2f8ec00b-e895-4e1b-932d-4d6efcd9e7bd /129.215.175.98 ztf-mirror.roe.ac.uk-0
ztf_20181219_programid1 10         1577            20859           19282           ztf-mirror.roe.ac.uk-1-4a0c5dcb-7c72-4d5c-8f01-5ab7aeef4209 /129.215.175.98 ztf-mirror.roe.ac.uk-1
ztf_20181219_programid1 11         1527            20858           19331           ztf-mirror.roe.ac.uk-1-d2737872-883a-44ce-8c86-82ce4930214f /129.215.175.98 ztf-mirror.roe.ac.uk-1
ztf_20181219_programid1 1          1784            20859           19075           ztf-mirror.roe.ac.uk-0-9a40a633-d756-4a78-8e38-5a33ef6b92c6 /129.215.175.98 ztf-mirror.roe.ac.uk-0
ztf_20181219_programid1 12         1567            20858           19291           ztf-mirror.roe.ac.uk-2-42f68bd4-59d8-4e64-945e-402152189b06 /129.215.175.98 ztf-mirror.roe.ac.uk-2
ztf_20181219_programid1 13         1525            20859           19334           ztf-mirror.roe.ac.uk-2-58361761-429d-4560-9abb-6283385965da /129.215.175.98 ztf-mirror.roe.ac.uk-2
ztf_20181219_programid1 2          1570            20858           19288           ztf-mirror.roe.ac.uk-1-4a0c5dcb-7c72-4d5c-8f01-5ab7aeef4209 /129.215.175.98 ztf-mirror.roe.ac.uk-1
ztf_20181219_programid1 3          1529            20859           19330           ztf-mirror.roe.ac.uk-1-d2737872-883a-44ce-8c86-82ce4930214f /129.215.175.98 ztf-mirror.roe.ac.uk-1
ztf_20181219_programid1 4          1573            20859           19286           ztf-mirror.roe.ac.uk-2-42f68bd4-59d8-4e64-945e-402152189b06 /129.215.175.98 ztf-mirror.roe.ac.uk-2
ztf_20181219_programid1 5          1526            20858           19332           ztf-mirror.roe.ac.uk-2-58361761-429d-4560-9abb-6283385965da /129.215.175.98 ztf-mirror.roe.ac.uk-2
ztf_20181219_programid1 6          2987            20858           17871           ztf-mirror.roe.ac.uk-3-5a92f773-6412-4dce-9d33-b1d965d43147 /129.215.175.98 ztf-mirror.roe.ac.uk-3
ztf_20181219_programid1 7          3076            20859           17783           ztf-mirror.roe.ac.uk-3-a15876c9-eb15-494e-83d6-648e0eea7730 /129.215.175.98 ztf-mirror.roe.ac.uk-3
ztf_20181219_programid1 8          1571            20858           19287           ztf-mirror.roe.ac.uk-0-2f8ec00b-e895-4e1b-932d-4d6efcd9e7bd /129.215.175.98 ztf-mirror.roe.ac.uk-0
ztf_20181219_programid1 9          1781            20859           19078           ztf-mirror.roe.ac.uk-0-9a40a633-d756-4a78-8e38-5a33ef6b92c6 /129.215.175.98 ztf-mirror.roe.ac.uk-0
Sun 23 Dec 16:37:22 GMT 2018
--STOP--


--START--
Sun 23 Dec 16:45:40 GMT 2018
TOPIC                   PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                 HOST            CLIENT-ID
ztf_20181219_programid1 0          4011            20858           16847           ztf-mirror.roe.ac.uk-0-2f8ec00b-e895-4e1b-932d-4d6efcd9e7bd /129.215.175.98 ztf-mirror.roe.ac.uk-0
ztf_20181219_programid1 10         4006            20859           16853           ztf-mirror.roe.ac.uk-1-4a0c5dcb-7c72-4d5c-8f01-5ab7aeef4209 /129.215.175.98 ztf-mirror.roe.ac.uk-1
ztf_20181219_programid1 11         3963            20858           16895           ztf-mirror.roe.ac.uk-1-d2737872-883a-44ce-8c86-82ce4930214f /129.215.175.98 ztf-mirror.roe.ac.uk-1
ztf_20181219_programid1 12         3996            20858           16862           ztf-mirror.roe.ac.uk-2-42f68bd4-59d8-4e64-945e-402152189b06 /129.215.175.98 ztf-mirror.roe.ac.uk-2
ztf_20181219_programid1 13         3976            20859           16883           ztf-mirror.roe.ac.uk-2-58361761-429d-4560-9abb-6283385965da /129.215.175.98 ztf-mirror.roe.ac.uk-2
ztf_20181219_programid1 1          3959            20859           16900           ztf-mirror.roe.ac.uk-0-9a40a633-d756-4a78-8e38-5a33ef6b92c6 /129.215.175.98 ztf-mirror.roe.ac.uk-0
ztf_20181219_programid1 2          4001            20858           16857           ztf-mirror.roe.ac.uk-1-4a0c5dcb-7c72-4d5c-8f01-5ab7aeef4209 /129.215.175.98 ztf-mirror.roe.ac.uk-1
ztf_20181219_programid1 3          3961            20859           16898           ztf-mirror.roe.ac.uk-1-d2737872-883a-44ce-8c86-82ce4930214f /129.215.175.98 ztf-mirror.roe.ac.uk-1
ztf_20181219_programid1 4          4003            20859           16856           ztf-mirror.roe.ac.uk-2-42f68bd4-59d8-4e64-945e-402152189b06 /129.215.175.98 ztf-mirror.roe.ac.uk-2
ztf_20181219_programid1 5          3973            20858           16885           ztf-mirror.roe.ac.uk-2-58361761-429d-4560-9abb-6283385965da /129.215.175.98 ztf-mirror.roe.ac.uk-2
ztf_20181219_programid1 6          7685            20858           13173           ztf-mirror.roe.ac.uk-3-5a92f773-6412-4dce-9d33-b1d965d43147 /129.215.175.98 ztf-mirror.roe.ac.uk-3
ztf_20181219_programid1 7          7769            20859           13090           ztf-mirror.roe.ac.uk-3-a15876c9-eb15-494e-83d6-648e0eea7730 /129.215.175.98 ztf-mirror.roe.ac.uk-3
ztf_20181219_programid1 8          4001            20858           16857           ztf-mirror.roe.ac.uk-0-2f8ec00b-e895-4e1b-932d-4d6efcd9e7bd /129.215.175.98 ztf-mirror.roe.ac.uk-0
ztf_20181219_programid1 9          3953            20859           16906           ztf-mirror.roe.ac.uk-0-9a40a633-d756-4a78-8e38-5a33ef6b92c6 /129.215.175.98 ztf-mirror.roe.ac.uk-0
Sun 23 Dec 16:45:48 GMT 2018
--STOP--


--START--
--STOP--


--START--
--STOP--


# -----------------------------------------------------
# Check the disc use on each Kafka node.
#[user@trop03]

    for vmname in ${kfnames[@]}
        do
            ssh \
                ${sshopts[*]} \
                ${sshuser:?}@${vmname:?} \
                    "
                    echo \"---- ---- ---- ----\"
                    echo \"[\$(hostname)][\$(date)]\"

                    echo \"---- ----\"
                    du -h \"/data1-01\"
                    echo \"---- ----\"
                    du -h \"/data1-02\"

                    echo "---- ----"
                    du -h \"/data2-01\"
                    echo "---- ----"
                    du -h \"/data2-02\"
                    "
        done

#
# Not using the new partitions yet ...

--START--
---- ---- ---- ----
[Stedigo][Sun 23 Dec 16:47:59 GMT 2018]
---- ----
0	/data1-01/__confluent.support.metrics-0
715M	/data1-01/ztf_20181205_programid1-6
716M	/data1-01/ztf_20181205_programid1-14
715M	/data1-01/ztf_20181205_programid1-12
716M	/data1-01/ztf_20181205_programid1-0
715M	/data1-01/ztf_20181205_programid1-4
716M	/data1-01/ztf_20181205_programid1-1
269M	/data1-01/ztf_20181209_programid1-7
269M	/data1-01/ztf_20181209_programid1-15
269M	/data1-01/ztf_20181209_programid1-14
269M	/data1-01/ztf_20181209_programid1-5
269M	/data1-01/ztf_20181209_programid1-12
269M	/data1-01/ztf_20181209_programid1-6
437M	/data1-01/ztf_20181210_programid1-0
437M	/data1-01/ztf_20181210_programid1-8
437M	/data1-01/ztf_20181210_programid1-9
437M	/data1-01/ztf_20181210_programid1-3
436M	/data1-01/ztf_20181210_programid1-5
437M	/data1-01/ztf_20181210_programid1-2
646M	/data1-01/ztf_20181212_programid1-2
646M	/data1-01/ztf_20181212_programid1-10
647M	/data1-01/ztf_20181212_programid1-12
646M	/data1-01/ztf_20181212_programid1-9
646M	/data1-01/ztf_20181212_programid1-7
646M	/data1-01/ztf_20181212_programid1-1
497M	/data1-01/ztf_20181213_programid1-10
497M	/data1-01/ztf_20181213_programid1-2
497M	/data1-01/ztf_20181213_programid1-9
496M	/data1-01/ztf_20181213_programid1-4
496M	/data1-01/ztf_20181213_programid1-1
496M	/data1-01/ztf_20181213_programid1-11
957M	/data1-01/ztf_20181214_programid1-8
957M	/data1-01/ztf_20181214_programid1-0
957M	/data1-01/ztf_20181214_programid1-5
958M	/data1-01/ztf_20181214_programid1-2
957M	/data1-01/ztf_20181214_programid1-9
957M	/data1-01/ztf_20181214_programid1-3
42M	/data1-01/ztf_20181215_programid1-9
42M	/data1-01/ztf_20181215_programid1-1
42M	/data1-01/ztf_20181215_programid1-15
42M	/data1-01/ztf_20181215_programid1-6
42M	/data1-01/ztf_20181215_programid1-0
42M	/data1-01/ztf_20181215_programid1-7
561M	/data1-01/ztf_20181216_programid1-1
560M	/data1-01/ztf_20181216_programid1-9
560M	/data1-01/ztf_20181216_programid1-3
561M	/data1-01/ztf_20181216_programid1-7
560M	/data1-01/ztf_20181216_programid1-15
560M	/data1-01/ztf_20181216_programid1-0
992M	/data1-01/ztf_20181217_programid1-2
991M	/data1-01/ztf_20181217_programid1-10
992M	/data1-01/ztf_20181217_programid1-12
991M	/data1-01/ztf_20181217_programid1-0
991M	/data1-01/ztf_20181217_programid1-13
993M	/data1-01/ztf_20181217_programid1-7
30G	/data1-01
---- ----
16K	/data1-02
---- ----
716M	/data2-01/ztf_20181205_programid1-2
716M	/data2-01/ztf_20181205_programid1-10
715M	/data2-01/ztf_20181205_programid1-11
716M	/data2-01/ztf_20181205_programid1-9
716M	/data2-01/ztf_20181205_programid1-7
715M	/data2-01/ztf_20181205_programid1-13
269M	/data2-01/ztf_20181209_programid1-3
269M	/data2-01/ztf_20181209_programid1-11
269M	/data2-01/ztf_20181209_programid1-0
269M	/data2-01/ztf_20181209_programid1-8
269M	/data2-01/ztf_20181209_programid1-2
269M	/data2-01/ztf_20181209_programid1-9
436M	/data2-01/ztf_20181210_programid1-12
436M	/data2-01/ztf_20181210_programid1-4
437M	/data2-01/ztf_20181210_programid1-15
437M	/data2-01/ztf_20181210_programid1-6
436M	/data2-01/ztf_20181210_programid1-14
437M	/data2-01/ztf_20181210_programid1-11
647M	/data2-01/ztf_20181212_programid1-14
647M	/data2-01/ztf_20181212_programid1-6
646M	/data2-01/ztf_20181212_programid1-11
646M	/data2-01/ztf_20181212_programid1-0
646M	/data2-01/ztf_20181212_programid1-13
646M	/data2-01/ztf_20181212_programid1-4
496M	/data2-01/ztf_20181213_programid1-6
496M	/data2-01/ztf_20181213_programid1-14
496M	/data2-01/ztf_20181213_programid1-12
497M	/data2-01/ztf_20181213_programid1-0
496M	/data2-01/ztf_20181213_programid1-13
496M	/data2-01/ztf_20181213_programid1-7
957M	/data2-01/ztf_20181214_programid1-4
957M	/data2-01/ztf_20181214_programid1-12
957M	/data2-01/ztf_20181214_programid1-11
957M	/data2-01/ztf_20181214_programid1-14
958M	/data2-01/ztf_20181214_programid1-15
958M	/data2-01/ztf_20181214_programid1-6
42M	/data2-01/ztf_20181215_programid1-5
42M	/data2-01/ztf_20181215_programid1-13
42M	/data2-01/ztf_20181215_programid1-8
42M	/data2-01/ztf_20181215_programid1-12
42M	/data2-01/ztf_20181215_programid1-3
42M	/data2-01/ztf_20181215_programid1-10
560M	/data2-01/ztf_20181216_programid1-13
560M	/data2-01/ztf_20181216_programid1-5
560M	/data2-01/ztf_20181216_programid1-6
560M	/data2-01/ztf_20181216_programid1-10
560M	/data2-01/ztf_20181216_programid1-8
560M	/data2-01/ztf_20181216_programid1-12
992M	/data2-01/ztf_20181217_programid1-14
992M	/data2-01/ztf_20181217_programid1-6
993M	/data2-01/ztf_20181217_programid1-11
992M	/data2-01/ztf_20181217_programid1-9
992M	/data2-01/ztf_20181217_programid1-4
992M	/data2-01/ztf_20181217_programid1-1
30G	/data2-01
---- ----
16K	/data2-02
---- ---- ---- ----
[Angece][Sun 23 Dec 16:47:59 GMT 2018]
---- ----
0	/data1-01/__confluent.support.metrics-0
715M	/data1-01/ztf_20181205_programid1-15
716M	/data1-01/ztf_20181205_programid1-7
715M	/data1-01/ztf_20181205_programid1-5
716M	/data1-01/ztf_20181205_programid1-10
715M	/data1-01/ztf_20181205_programid1-13
716M	/data1-01/ztf_20181205_programid1-14
269M	/data1-01/ztf_20181209_programid1-4
269M	/data1-01/ztf_20181209_programid1-12
269M	/data1-01/ztf_20181209_programid1-13
269M	/data1-01/ztf_20181209_programid1-7
269M	/data1-01/ztf_20181209_programid1-15
269M	/data1-01/ztf_20181209_programid1-6
437M	/data1-01/ztf_20181210_programid1-13
436M	/data1-01/ztf_20181210_programid1-5
436M	/data1-01/ztf_20181210_programid1-12
437M	/data1-01/ztf_20181210_programid1-3
437M	/data1-01/ztf_20181210_programid1-10
437M	/data1-01/ztf_20181210_programid1-8
646M	/data1-01/ztf_20181212_programid1-15
646M	/data1-01/ztf_20181212_programid1-7
646M	/data1-01/ztf_20181212_programid1-8
646M	/data1-01/ztf_20181212_programid1-2
646M	/data1-01/ztf_20181212_programid1-10
646M	/data1-01/ztf_20181212_programid1-1
496M	/data1-01/ztf_20181213_programid1-7
496M	/data1-01/ztf_20181213_programid1-15
496M	/data1-01/ztf_20181213_programid1-13
497M	/data1-01/ztf_20181213_programid1-10
496M	/data1-01/ztf_20181213_programid1-8
497M	/data1-01/ztf_20181213_programid1-2
957M	/data1-01/ztf_20181214_programid1-5
957M	/data1-01/ztf_20181214_programid1-13
957M	/data1-01/ztf_20181214_programid1-7
958M	/data1-01/ztf_20181214_programid1-15
958M	/data1-01/ztf_20181214_programid1-6
957M	/data1-01/ztf_20181214_programid1-0
42M	/data1-01/ztf_20181215_programid1-6
42M	/data1-01/ztf_20181215_programid1-14
42M	/data1-01/ztf_20181215_programid1-9
42M	/data1-01/ztf_20181215_programid1-13
42M	/data1-01/ztf_20181215_programid1-4
42M	/data1-01/ztf_20181215_programid1-11
560M	/data1-01/ztf_20181216_programid1-10
560M	/data1-01/ztf_20181216_programid1-2
561M	/data1-01/ztf_20181216_programid1-7
561M	/data1-01/ztf_20181216_programid1-1
560M	/data1-01/ztf_20181216_programid1-12
560M	/data1-01/ztf_20181216_programid1-9
993M	/data1-01/ztf_20181217_programid1-15
993M	/data1-01/ztf_20181217_programid1-7
991M	/data1-01/ztf_20181217_programid1-8
992M	/data1-01/ztf_20181217_programid1-2
991M	/data1-01/ztf_20181217_programid1-13
992M	/data1-01/ztf_20181217_programid1-1
30G	/data1-01
---- ----
16K	/data1-02
---- ----
715M	/data2-01/ztf_20181205_programid1-11
715M	/data2-01/ztf_20181205_programid1-3
716M	/data2-01/ztf_20181205_programid1-8
716M	/data2-01/ztf_20181205_programid1-2
715M	/data2-01/ztf_20181205_programid1-4
716M	/data2-01/ztf_20181205_programid1-1
269M	/data2-01/ztf_20181209_programid1-0
269M	/data2-01/ztf_20181209_programid1-8
269M	/data2-01/ztf_20181209_programid1-3
269M	/data2-01/ztf_20181209_programid1-10
269M	/data2-01/ztf_20181209_programid1-1
269M	/data2-01/ztf_20181209_programid1-9
437M	/data2-01/ztf_20181210_programid1-9
437M	/data2-01/ztf_20181210_programid1-1
437M	/data2-01/ztf_20181210_programid1-15
437M	/data2-01/ztf_20181210_programid1-6
437M	/data2-01/ztf_20181210_programid1-0
437M	/data2-01/ztf_20181210_programid1-7
646M	/data2-01/ztf_20181212_programid1-11
646M	/data2-01/ztf_20181212_programid1-3
647M	/data2-01/ztf_20181212_programid1-14
646M	/data2-01/ztf_20181212_programid1-5
646M	/data2-01/ztf_20181212_programid1-13
646M	/data2-01/ztf_20181212_programid1-4
496M	/data2-01/ztf_20181213_programid1-3
496M	/data2-01/ztf_20181213_programid1-11
496M	/data2-01/ztf_20181213_programid1-4
496M	/data2-01/ztf_20181213_programid1-1
496M	/data2-01/ztf_20181213_programid1-14
496M	/data2-01/ztf_20181213_programid1-5
958M	/data2-01/ztf_20181214_programid1-1
957M	/data2-01/ztf_20181214_programid1-9
958M	/data2-01/ztf_20181214_programid1-10
957M	/data2-01/ztf_20181214_programid1-8
957M	/data2-01/ztf_20181214_programid1-12
957M	/data2-01/ztf_20181214_programid1-3
42M	/data2-01/ztf_20181215_programid1-2
42M	/data2-01/ztf_20181215_programid1-10
42M	/data2-01/ztf_20181215_programid1-12
42M	/data2-01/ztf_20181215_programid1-0
42M	/data2-01/ztf_20181215_programid1-7
42M	/data2-01/ztf_20181215_programid1-1
560M	/data2-01/ztf_20181216_programid1-6
560M	/data2-01/ztf_20181216_programid1-14
560M	/data2-01/ztf_20181216_programid1-13
560M	/data2-01/ztf_20181216_programid1-4
560M	/data2-01/ztf_20181216_programid1-11
560M	/data2-01/ztf_20181216_programid1-0
993M	/data2-01/ztf_20181217_programid1-11
993M	/data2-01/ztf_20181217_programid1-3
992M	/data2-01/ztf_20181217_programid1-14
992M	/data2-01/ztf_20181217_programid1-5
992M	/data2-01/ztf_20181217_programid1-4
991M	/data2-01/ztf_20181217_programid1-10
30G	/data2-01
---- ----
16K	/data2-02
---- ---- ---- ----
[Edwalafia][Sun 23 Dec 16:47:59 GMT 2018]
---- ----
0	/data1-01/__confluent.support.metrics-0
715M	/data1-01/ztf_20181205_programid1-12
715M	/data1-01/ztf_20181205_programid1-4
715M	/data1-01/ztf_20181205_programid1-5
715M	/data1-01/ztf_20181205_programid1-15
715M	/data1-01/ztf_20181205_programid1-6
716M	/data1-01/ztf_20181205_programid1-14
269M	/data1-01/ztf_20181209_programid1-1
269M	/data1-01/ztf_20181209_programid1-9
269M	/data1-01/ztf_20181209_programid1-10
269M	/data1-01/ztf_20181209_programid1-4
269M	/data1-01/ztf_20181209_programid1-11
269M	/data1-01/ztf_20181209_programid1-12
437M	/data1-01/ztf_20181210_programid1-10
437M	/data1-01/ztf_20181210_programid1-2
437M	/data1-01/ztf_20181210_programid1-9
437M	/data1-01/ztf_20181210_programid1-13
436M	/data1-01/ztf_20181210_programid1-4
437M	/data1-01/ztf_20181210_programid1-11
647M	/data1-01/ztf_20181212_programid1-12
646M	/data1-01/ztf_20181212_programid1-4
646M	/data1-01/ztf_20181212_programid1-11
646M	/data1-01/ztf_20181212_programid1-2
646M	/data1-01/ztf_20181212_programid1-9
646M	/data1-01/ztf_20181212_programid1-3
497M	/data1-01/ztf_20181213_programid1-0
496M	/data1-01/ztf_20181213_programid1-8
496M	/data1-01/ztf_20181213_programid1-6
496M	/data1-01/ztf_20181213_programid1-14
496M	/data1-01/ztf_20181213_programid1-5
496M	/data1-01/ztf_20181213_programid1-15
957M	/data1-01/ztf_20181214_programid1-14
958M	/data1-01/ztf_20181214_programid1-6
957M	/data1-01/ztf_20181214_programid1-4
957M	/data1-01/ztf_20181214_programid1-11
957M	/data1-01/ztf_20181214_programid1-9
957M	/data1-01/ztf_20181214_programid1-13
42M	/data1-01/ztf_20181215_programid1-3
42M	/data1-01/ztf_20181215_programid1-11
42M	/data1-01/ztf_20181215_programid1-5
42M	/data1-01/ztf_20181215_programid1-13
42M	/data1-01/ztf_20181215_programid1-4
42M	/data1-01/ztf_20181215_programid1-14
561M	/data1-01/ztf_20181216_programid1-7
560M	/data1-01/ztf_20181216_programid1-15
560M	/data1-01/ztf_20181216_programid1-10
561M	/data1-01/ztf_20181216_programid1-1
560M	/data1-01/ztf_20181216_programid1-8
560M	/data1-01/ztf_20181216_programid1-2
992M	/data1-01/ztf_20181217_programid1-12
992M	/data1-01/ztf_20181217_programid1-4
993M	/data1-01/ztf_20181217_programid1-11
992M	/data1-01/ztf_20181217_programid1-2
992M	/data1-01/ztf_20181217_programid1-9
993M	/data1-01/ztf_20181217_programid1-3
30G	/data1-01
---- ----
16K	/data1-02
---- ----
716M	/data2-01/ztf_20181205_programid1-8
716M	/data2-01/ztf_20181205_programid1-0
715M	/data2-01/ztf_20181205_programid1-11
716M	/data2-01/ztf_20181205_programid1-2
716M	/data2-01/ztf_20181205_programid1-9
715M	/data2-01/ztf_20181205_programid1-3
269M	/data2-01/ztf_20181209_programid1-13
269M	/data2-01/ztf_20181209_programid1-5
269M	/data2-01/ztf_20181209_programid1-0
269M	/data2-01/ztf_20181209_programid1-7
269M	/data2-01/ztf_20181209_programid1-14
269M	/data2-01/ztf_20181209_programid1-2
437M	/data2-01/ztf_20181210_programid1-6
436M	/data2-01/ztf_20181210_programid1-14
436M	/data2-01/ztf_20181210_programid1-12
437M	/data2-01/ztf_20181210_programid1-0
437M	/data2-01/ztf_20181210_programid1-7
437M	/data2-01/ztf_20181210_programid1-1
646M	/data2-01/ztf_20181212_programid1-8
646M	/data2-01/ztf_20181212_programid1-0
647M	/data2-01/ztf_20181212_programid1-14
646M	/data2-01/ztf_20181212_programid1-5
646M	/data2-01/ztf_20181212_programid1-15
647M	/data2-01/ztf_20181212_programid1-6
496M	/data2-01/ztf_20181213_programid1-12
496M	/data2-01/ztf_20181213_programid1-4
497M	/data2-01/ztf_20181213_programid1-9
496M	/data2-01/ztf_20181213_programid1-3
496M	/data2-01/ztf_20181213_programid1-11
497M	/data2-01/ztf_20181213_programid1-2
958M	/data2-01/ztf_20181214_programid1-10
958M	/data2-01/ztf_20181214_programid1-2
957M	/data2-01/ztf_20181214_programid1-7
958M	/data2-01/ztf_20181214_programid1-1
957M	/data2-01/ztf_20181214_programid1-12
957M	/data2-01/ztf_20181214_programid1-0
42M	/data2-01/ztf_20181215_programid1-15
42M	/data2-01/ztf_20181215_programid1-7
42M	/data2-01/ztf_20181215_programid1-8
42M	/data2-01/ztf_20181215_programid1-2
42M	/data2-01/ztf_20181215_programid1-10
42M	/data2-01/ztf_20181215_programid1-1
560M	/data2-01/ztf_20181216_programid1-3
560M	/data2-01/ztf_20181216_programid1-11
560M	/data2-01/ztf_20181216_programid1-13
560M	/data2-01/ztf_20181216_programid1-4
560M	/data2-01/ztf_20181216_programid1-14
560M	/data2-01/ztf_20181216_programid1-5
991M	/data2-01/ztf_20181217_programid1-8
991M	/data2-01/ztf_20181217_programid1-0
992M	/data2-01/ztf_20181217_programid1-14
992M	/data2-01/ztf_20181217_programid1-5
993M	/data2-01/ztf_20181217_programid1-15
992M	/data2-01/ztf_20181217_programid1-6
30G	/data2-01
---- ----
16K	/data2-02
---- ---- ---- ----
[Onoza][Sun 23 Dec 16:48:00 GMT 2018]
---- ----
715M	/data1-01/ztf_20181205_programid1-5
715M	/data1-01/ztf_20181205_programid1-13
716M	/data1-01/ztf_20181205_programid1-8
715M	/data1-01/ztf_20181205_programid1-12
715M	/data1-01/ztf_20181205_programid1-3
716M	/data1-01/ztf_20181205_programid1-10
269M	/data1-01/ztf_20181209_programid1-10
269M	/data1-01/ztf_20181209_programid1-2
269M	/data1-01/ztf_20181209_programid1-3
269M	/data1-01/ztf_20181209_programid1-4
269M	/data1-01/ztf_20181209_programid1-11
269M	/data1-01/ztf_20181209_programid1-5
437M	/data1-01/ztf_20181210_programid1-15
437M	/data1-01/ztf_20181210_programid1-7
437M	/data1-01/ztf_20181210_programid1-13
436M	/data1-01/ztf_20181210_programid1-4
437M	/data1-01/ztf_20181210_programid1-8
436M	/data1-01/ztf_20181210_programid1-5
646M	/data1-01/ztf_20181212_programid1-5
646M	/data1-01/ztf_20181212_programid1-13
646M	/data1-01/ztf_20181212_programid1-8
647M	/data1-01/ztf_20181212_programid1-12
647M	/data1-01/ztf_20181212_programid1-6
646M	/data1-01/ztf_20181212_programid1-10
497M	/data1-01/ztf_20181213_programid1-9
496M	/data1-01/ztf_20181213_programid1-1
496M	/data1-01/ztf_20181213_programid1-12
496M	/data1-01/ztf_20181213_programid1-3
497M	/data1-01/ztf_20181213_programid1-10
496M	/data1-01/ztf_20181213_programid1-8
957M	/data1-01/ztf_20181214_programid1-7
958M	/data1-01/ztf_20181214_programid1-15
958M	/data1-01/ztf_20181214_programid1-10
958M	/data1-01/ztf_20181214_programid1-1
957M	/data1-01/ztf_20181214_programid1-5
958M	/data1-01/ztf_20181214_programid1-2
42M	/data1-01/ztf_20181215_programid1-8
42M	/data1-01/ztf_20181215_programid1-0
42M	/data1-01/ztf_20181215_programid1-15
42M	/data1-01/ztf_20181215_programid1-2
42M	/data1-01/ztf_20181215_programid1-6
42M	/data1-01/ztf_20181215_programid1-14
560M	/data1-01/ztf_20181216_programid1-4
560M	/data1-01/ztf_20181216_programid1-12
560M	/data1-01/ztf_20181216_programid1-6
560M	/data1-01/ztf_20181216_programid1-14
560M	/data1-01/ztf_20181216_programid1-5
560M	/data1-01/ztf_20181216_programid1-15
992M	/data1-01/ztf_20181217_programid1-5
991M	/data1-01/ztf_20181217_programid1-13
991M	/data1-01/ztf_20181217_programid1-8
992M	/data1-01/ztf_20181217_programid1-12
993M	/data1-01/ztf_20181217_programid1-3
991M	/data1-01/ztf_20181217_programid1-10
30G	/data1-01
---- ----
16K	/data1-02
---- ----
716M	/data2-01/ztf_20181205_programid1-9
716M	/data2-01/ztf_20181205_programid1-1
715M	/data2-01/ztf_20181205_programid1-15
715M	/data2-01/ztf_20181205_programid1-6
716M	/data2-01/ztf_20181205_programid1-0
716M	/data2-01/ztf_20181205_programid1-7
269M	/data2-01/ztf_20181209_programid1-14
269M	/data2-01/ztf_20181209_programid1-6
269M	/data2-01/ztf_20181209_programid1-13
269M	/data2-01/ztf_20181209_programid1-1
269M	/data2-01/ztf_20181209_programid1-8
269M	/data2-01/ztf_20181209_programid1-15
437M	/data2-01/ztf_20181210_programid1-3
437M	/data2-01/ztf_20181210_programid1-11
437M	/data2-01/ztf_20181210_programid1-10
437M	/data2-01/ztf_20181210_programid1-1
436M	/data2-01/ztf_20181210_programid1-14
437M	/data2-01/ztf_20181210_programid1-2
646M	/data2-01/ztf_20181212_programid1-9
646M	/data2-01/ztf_20181212_programid1-1
646M	/data2-01/ztf_20181212_programid1-15
646M	/data2-01/ztf_20181212_programid1-0
646M	/data2-01/ztf_20181212_programid1-3
646M	/data2-01/ztf_20181212_programid1-7
496M	/data2-01/ztf_20181213_programid1-13
496M	/data2-01/ztf_20181213_programid1-5
496M	/data2-01/ztf_20181213_programid1-6
497M	/data2-01/ztf_20181213_programid1-0
496M	/data2-01/ztf_20181213_programid1-7
496M	/data2-01/ztf_20181213_programid1-15
957M	/data2-01/ztf_20181214_programid1-11
957M	/data2-01/ztf_20181214_programid1-3
957M	/data2-01/ztf_20181214_programid1-4
957M	/data2-01/ztf_20181214_programid1-8
957M	/data2-01/ztf_20181214_programid1-14
957M	/data2-01/ztf_20181214_programid1-13
42M	/data2-01/ztf_20181215_programid1-12
42M	/data2-01/ztf_20181215_programid1-4
42M	/data2-01/ztf_20181215_programid1-5
42M	/data2-01/ztf_20181215_programid1-9
42M	/data2-01/ztf_20181215_programid1-3
42M	/data2-01/ztf_20181215_programid1-11
560M	/data2-01/ztf_20181216_programid1-8
560M	/data2-01/ztf_20181216_programid1-0
560M	/data2-01/ztf_20181216_programid1-3
560M	/data2-01/ztf_20181216_programid1-11
560M	/data2-01/ztf_20181216_programid1-2
560M	/data2-01/ztf_20181216_programid1-9
992M	/data2-01/ztf_20181217_programid1-9
992M	/data2-01/ztf_20181217_programid1-1
993M	/data2-01/ztf_20181217_programid1-15
992M	/data2-01/ztf_20181217_programid1-6
991M	/data2-01/ztf_20181217_programid1-0
993M	/data2-01/ztf_20181217_programid1-7
30G	/data2-01
---- ----
16K	/data2-02
--STOP--


# -----------------------------------------------------
# Check the disc space on each Kafka node.
#[user@trop03]

    for vmname in ${kfnames[@]}
        do
            ssh \
                ${sshopts[*]} \
                ${sshuser:?}@${vmname:?} \
                    "
                    echo \"---- ---- ---- ----\"
                    echo \"[\$(hostname)][\$(date)]\"
                    echo \"---- ----\"

                    df -h /
                    echo \"---- ----\"
                    df -h \"/data1-01\"
                    echo \"---- ----\"
                    df -h \"/data1-02\"

                    echo "---- ----"
                    df -h \"/data2-01\"
                    echo "---- ----"
                    df -h \"/data2-02\"
                    "
        done


--START--
---- ---- ---- ----
[Stedigo][Sun 23 Dec 16:44:56 GMT 2018]
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda3       6.8G  5.2G  1.2G  83% /
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdc         32G   31G  4.6M 100% /data1-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vde         64G   17M   62G   1% /data1-02
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdd         32G   31G  3.3M 100% /data2-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdf         64G   17M   62G   1% /data2-02
---- ---- ---- ----
[Angece][Sun 23 Dec 16:44:56 GMT 2018]
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda3       6.8G  5.2G  1.2G  83% /
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdc         32G   31G  4.0M 100% /data1-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vde         64G   17M   62G   1% /data1-02
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdd         32G   31G  4.1M 100% /data2-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdf         64G   17M   62G   1% /data2-02
---- ---- ---- ----
[Edwalafia][Sun 23 Dec 16:44:57 GMT 2018]
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda3       6.8G  5.3G  1.1G  84% /
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdc         32G   31G  6.1M 100% /data1-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vde         64G   17M   62G   1% /data1-02
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdd         32G   31G  3.8M 100% /data2-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdf         64G   17M   62G   1% /data2-02
---- ---- ---- ----
[Onoza][Sun 23 Dec 16:44:57 GMT 2018]
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda3       6.8G  5.2G  1.1G  84% /
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdc         32G   31G  4.7M 100% /data1-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vde         64G   17M   62G   1% /data1-02
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdd         32G   31G  4.9M 100% /data2-01
---- ----
Filesystem      Size  Used Avail Use% Mounted on
/dev/vdf         64G   17M   62G   1% /data2-02
--STOP--


# -----------------------------------------------------
# Kafka services fail - out of disc space.
#[user@trop03]

--START--
[2018-12-23 16:49:46,181] ERROR Error while appending records to ztf_20181219_programid1-4 in dir /data1-02 (kafka.server.LogDirFailureChannel)
java.io.IOException: No space left on device
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
    ....

[2018-12-23 16:49:46,181] ERROR Error while appending records to ztf_20181219_programid1-5 in dir /data1-02 (kafka.server.LogDirFailureChannel)
java.io.IOException: No space left on device
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
    ....

[2018-12-23 16:49:46,228] INFO [ReplicaManager broker=3] Stopping serving replicas in dir /data1-02 (kafka.server.ReplicaManager)
[2018-12-23 16:49:46,230] ERROR [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error while processing data for partition ztf_20181219_programid1-4 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.KafkaStorageException: Error while appending records to ztf_20181219_programid1-4 in dir /data1-02
Caused by: java.io.IOException: No space left on device
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
    ....

[2018-12-23 16:49:46,230] ERROR [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error while processing data for partition ztf_20181219_programid1-5 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.KafkaStorageException: Error while appending records to ztf_20181219_programid1-5 in dir /data1-02
Caused by: java.io.IOException: No space left on device
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
    ....

[2018-12-23 16:49:46,247] ERROR Error while appending records to ztf_20181219_programid1-8 in dir /data2-02 (kafka.server.LogDirFailureChannel)
java.io.IOException: No space left on device
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
    ....

[2018-12-23 16:49:46,260] ERROR Error while appending records to ztf_20181219_programid1-13 in dir /data2-02 (kafka.server.LogDirFailureChannel)
java.io.IOException: No space left on device
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
    ....

[2018-12-23 16:49:46,264] ERROR [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error while processing data for partition ztf_20181219_programid1-8 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.KafkaStorageException: Error while appending records to ztf_20181219_programid1-8 in dir /data2-02
Caused by: java.io.IOException: No space left on device
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
    ....

[2018-12-23 16:49:46,265] ERROR [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error while processing data for partition ztf_20181219_programid1-13 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.KafkaStorageException: Error while appending records to ztf_20181219_programid1-13 in dir /data2-02
Caused by: java.io.IOException: No space left on device
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
    ....

[2018-12-23 16:49:46,278] ERROR Error while appending records to ztf_20181219_programid1-1 in dir /data2-02 (kafka.server.LogDirFailureChannel)
java.io.IOException: No space left on device
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
    ....

[2018-12-23 16:49:46,280] ERROR [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error while processing data for partition ztf_20181219_programid1-1 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.KafkaStorageException: Error while appending records to ztf_20181219_programid1-1 in dir /data2-02
Caused by: java.io.IOException: No space left on device
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
    ....

[2018-12-23 16:49:46,283] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions ztf_20181219_programid1-11,ztf_20181219_programid1-5,ztf_20181219_programid1-2,ztf_20181219_programid1-3,ztf_20181219_programid1-10,ztf_20181219_programid1-4 (kafka.server.ReplicaFetcherManager)
#
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGBUS (0x7) at pc=0x00007f18b71c7805, pid=1, tid=0x00007f1873789700
#
# JRE version: OpenJDK Runtime Environment (8.0_172-b01) (build 1.8.0_172-b01)
# Java VM: OpenJDK 64-Bit Server VM (25.172-b01 mixed mode linux-amd64 compressed oops)
# Problematic frame:
[thread 139739235612416 also had an error]
  CompileBroker::collect_statistics(CompilerThread*, elapsedTimer, CompileTask*)+0x4e5
#
# Core dump written. Default location: //core or core.1
#
# An error report file with more information is saved as:
# //hs_err_pid1.log
--STOP--


-START--
-STOP--


-START--
-STOP--


-START--
-STOP--


-START--
-STOP--

